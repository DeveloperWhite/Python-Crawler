# 爬虫基础
# 准备一个网站
# url= 'http://www.baidu.com'
from urllib.request import urlopen
url = 'http://www.baidu.com'
resp = urlopen(url) # 通过urlopen方法打开url
print(resp.read().decode('utf-8'))
# 不是有所的网站把数据直接展示在页面源代码上的
# 第二种请求方式：
# 输入网址后，服务器会返回一个页面源代码（可能会缺少一些数据）
# 在一个特殊情况下，触发一个新的请求
# 这个新的请求，专门用来请求数据
# 服务端返回数据，浏览器执行一些脚本，把数据渲染到页面上

# A.服务器渲染全部数据
# B.服务器渲染部分数据 省钱，用户体验好，爬虫见得多（数据不在页面源代码上）京东，淘宝，拼多多
# 需要想办法看到真正加载数据的那个请求，然后提取数据

# F12查看网页
# 我们的程序拿到的是"页面源代码"，不能以Element为准，我们要以页面源代码为准
# Element：看到的代码是经过脚本，浏览器运行之后的东西（当前的状态），页面源代码和Element是不一样的，所以有时候请求的是页面源代码，导致有些数据拿不到
# Console：能够写代码，能够执行代码(JS代码)
# Sources：网页加载的时候需要用到的东西，比如图片，CSS，JS，HTML资源都有，后续经常会用到
# Network：抓包工具，可以看到所有的请求，每个请求可以理解为是数据包，这个抓包工具就能抓数据包

# http协议






